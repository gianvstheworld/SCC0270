{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 6 TEORIA - Regularização, Normalização e Transferência de Aprendizado\n",
    "\n",
    "Aula6 - Aula Presencial\n",
    "\n",
    "---\n",
    "\n",
    "## Regularização, Normalização e Transferência de Aprendizado\n",
    "\n",
    "- Treinando redes profundas em cenários reais\n",
    "    - Suposições para convergência e aprendizado\n",
    "    - Estratégias para melhorar generalização\n",
    "    - Normalização de dados\n",
    "- Transferência de apredendizado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algumas suposições feitas\n",
    "\n",
    "- Dados de treinamento \n",
    "    - Limpos\n",
    "    - Representativos e bem definidos com relação à tarefa: classes, valores da regressão, etc.\n",
    "    - Baixa taxa de erros de rótulo\n",
    "    - Quantidade de dados é suficiente \n",
    "- E se não for possível?\n",
    "    - Riscos: _overfitting_, baixa generalização, maior dificuldade no treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexidade de modelos\n",
    "\n",
    "- Lembrando: Aprendizado de Máquina pode ser formulado como sendo aprender os parâmetros de $f : X -> Y$\n",
    "- Um algoritmo ajusta $f$ a partir de um espaço de funções admissíveis $F$:\n",
    "    - \"muitas\" funções: mais graus de liberdade, menor garantia de convergência, possível overfitting;\n",
    "    - \"poucas\" funções: menos grau de liberdade, maior garantia de convergência, possível underfitting\n",
    "\n",
    "### Erros quando definindo o espaço de funções admissíveis\n",
    "\n",
    "<img src=\"Imagens/erros.png\" width=\"500\"> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo: conv.layers\n",
    "\n",
    "* Nós podemos interpretar cada camada da rede neural como sendo um detector de padrões em um certo campo receptivo local\n",
    "    * Exemplo dos digitos\n",
    "\n",
    "- Na primeira camada cada neurônio é especialista em uma certa região, montando um mapa de ativação\n",
    "    - A soma deles cobre toda a área da imagem e nesse caso, forma o dígito 7\n",
    "\n",
    "* A segunda camada convolucional é especialista em padrões geométricos, do tipo padrões horizontais, verticais e diagonais\n",
    "    * <img src=\"conv_layers.jpg\" width=\"300\"> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de parâmetros CNNs\n",
    "\n",
    "* n_params = [(k * k * p) + 1 (bias)] * d\n",
    "    * Peso dos filtros: k * k * p\n",
    "    * Número de filtros/neuronios: d\n",
    "        * Cada um gera um mapa de ativação\n",
    "    * + 1 é o termo bias de cada filtro\n",
    "\n",
    "- Exemplo: entrada 32 * 32 * 3 e 3 camadas\n",
    "    - Conv.layer 1: k = 5 e d = 8\n",
    "    - Conv.layer 2: k = 3 e d = 16\n",
    "    - Conv.layer 3: k = 1 e d = 32\n",
    "\n",
    "* \\# params Conv.layer 1 = [(5 * 5 * 3) + 1] * 8 = 608\n",
    "* \\# params Conv.layer 2 = [(3 * 3 * 8) + 1] * 16 = 1168\n",
    "* \\# params Conv.layer 3 = [(1 * 1 * 16) + 1] * 32 = 544\n",
    "\n",
    "- obs: Por que usar um filtro 1 por 1? Ele faz uma convolução só em profundidade, combinando cada cada pixel de cada imagem na mesma posição \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "* Opera sobre cada mapa de ativação, reduzindo a dimensão lateral\n",
    "    * Max pooling: operação de máximo local\n",
    "    * Average pooling: operação de média local\n",
    "\n",
    "- Exemplo:\n",
    "    - <img src=\"max_pooling.jpg\" width=\"400\"> \n",
    "\n",
    "* *obs: usar stride > 1 pode substituir o pooling*\n",
    "\n",
    "-  Reduzir o tamanho da entrada permite que o filtro opere em **regiões maiores da imagem**\n",
    "    - Empilhamento de camadas convolucionais aumenta o campo receptivo local não necessitando manter a resolução de entrada\n",
    "    - No exemplo o uso de filtros fez com que o mesmo filtro em um primeiro momento que pegava a íris da pessoa, na ultima imagem passou a pegar quase metade do rosto dela\n",
    "    - <img src=\"pooling.jpg\" width=\"400\"> \n",
    "\n",
    "### Global Pooling\n",
    "\n",
    "* Obtém um valor por canal, como se o tamanho de pool fosse igual as dimensões laterais\n",
    "    * Pooling normal: imagem 40x40, pooling de 2x2 -> imagem final de 20x20\n",
    "    * Global pooling: imagem 40x40, pooling de 40x40 -> imagem final de 1x1\n",
    "\n",
    "- A saída será a média (ou máximo) de uma matriz com só as dimensões de cada canal\n",
    "    - Exemplo: numa entrada com 40 × 40 × 100, a saída será 100 dimensões\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camadas densas e saída\n",
    "\n",
    "* Aplicando o pooling já visto com as convoluções\n",
    "    * <img src=\"CNN.jpg\" width=\"600\"> \n",
    "\n",
    "- No fim, aplicamos uma **camada densa fully connected (FC)**\n",
    "    - Similiar a de uma MultiLayer Perceptron\n",
    "    - Pode ser vista como uma projeção dos dados em uma dimensionalidade arbitrária\n",
    "    - <img src=\"CNN_comFC.jpg\" width=\"600\">\n",
    "\n",
    "* *obs: camada densa pode ser do tipo flatten -> transformar várias camadas em um só vetor*\n",
    "\n",
    "- **Saída**: comumente densa (ex: classificação e regressão)\n",
    "    - Pode ser vista como um vetor de distribuição de probabilidaaes (tipo softmax)\n",
    "    - Não é densa em redes completamente convolucionas (Fully Convolutional Newtowrks, FCN) que serão vistas pra frente\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

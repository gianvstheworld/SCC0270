{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AULA 4 TEORIA - Redes Convolucionais\n",
    "\n",
    "Aula 4 - Aula Assíncrona\n",
    "\n",
    "---\n",
    "\n",
    "## Redes Neurais Convolucionais (CNNs)\n",
    "\n",
    "- Camadas totalmente conectadas/densas vs Convolucionais\n",
    "- Convolução para imagens\n",
    "- Padding, Stride\n",
    "- Subamostragem (Pooling)\n",
    "- Mapas de ativação (activation/feature maps)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolução\n",
    "\n",
    "- Operador que visa realizar uma combinação linear de valores locais da entrada\n",
    "    - Centrado em uma posição (x,y), gera como saída um único valor de saída\n",
    "\n",
    "* obs: na prática e nos exemplos será usada a **Correlação Cruzada** e não uma convolução na teoria, uma vez que a convolução pede um \"flip\" nos eixos do filtro, o que acaba sendo mais custoso e produz resultados semelhantes da correlação cruzada\n",
    "    * Os frameworks e as técnicas atuais aplicam a correlação cruzada sob nome de convolução\n",
    "\n",
    "- <img src=\"convolucao1.jpg\" width=\"500\"> \n",
    "- <img src=\"convolucao2.jpg\" width=\"500\"> \n",
    "- 7x7 -> 5x5\n",
    "\n",
    "* E se quisermos que a entrada e saída tenha o **mesmo tamanho**?  \n",
    "    * Adiconamos um zero-padding de borda na entrada, aumentando ela em duas dimensões (1 para cada dimensão) com uma fileira só de zeros. Assim mesmo que o conteúdo da rede mude, a mudança é pequena e garantimos entrada e saída de mesmo tamanho, caso seja necessário\n",
    "    * <img src=\"padding_convoluca.jpg\" width=\"500\"> \n",
    "\n",
    "- **Convolução em profundidade:** entrada com vários canais\n",
    "    - Filtro k * k * p, sendo p a quantidade de canais da entrada\n",
    "    - Em uma imagem 3 canais com 3 matrizes diferentes são usados, cada qual representando um dos canais RGB. No fim, o resultado de cada canal é somado produzindo uma única saída\n",
    "    - <img src=\"conv_canal.jpg\" width=\"400\"> \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada Convolucional para redes neurais\n",
    "\n",
    "- Filtro (kernel ou neurônio convolucional) w com tamanho k * k * p\n",
    "    - Cada neuronio realiza a convoluçaõ da entrada e gera um volume (tensor) de saída\n",
    "\n",
    "* Centrado em um pixel específico, temos: w x + b\n",
    "    * O bias é inserido depois na convolução\n",
    "\n",
    "### Mapa de ativação\n",
    "\n",
    "* O resultado da convolução é chamad de **Mapa de ativação** e são obtidos após a convolução com a aplicação de uma função de ativação (ex ReLU)\n",
    "    * Empilhados formam um tensor que será a entrada da prox camada\n",
    "    * <img src=\"feature_,map.jpg\" width=\"600\"> \n",
    "\n",
    "### Como projetar uma CNN?\n",
    "\n",
    "* Deve levar em conta:\n",
    "    * **Tamanho da entrada** (largura, altura e profundidade)\n",
    "    * **Tamanho do filtro**\n",
    "        * Profundidade igual da entrada\n",
    "        * Altura e largura afetam o campo receptivo local\n",
    "    * **Stride** (passo nas duas direções)\n",
    "        * 1: todos pixels filtrados pelo neuronio\n",
    "        * \\> 1: salta um numero de pixels e determinada direção (convolução)\n",
    "            * Saída com tamanho reduzido\n",
    "\n",
    "- Stride é o passo que vc vai dar entre os pixels que vc vai chamar de central\n",
    "    - Exemplo: stride (2,2): varre de 2 em 2 horizontalmente até acabar, pula duas linhas verticais e continua varrendo horizontalmente\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo: conv.layers\n",
    "\n",
    "* Nós podemos interpretar cada camada da rede neural como sendo um detector de padrões em um certo campo receptivo local\n",
    "    * Exemplo dos digitos\n",
    "\n",
    "- Na primeira camada cada neurônio é especialista em uma certa região, montando um mapa de ativação\n",
    "    - A soma deles cobre toda a área da imagem e nesse caso, forma o dígito 7\n",
    "\n",
    "* A segunda camada convolucional é especialista em padrões geométricos, do tipo padrões horizontais, verticais e diagonais\n",
    "    * <img src=\"conv_layers.jpg\" width=\"300\"> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de parâmetros CNNs\n",
    "\n",
    "* n_params = [(k * k * p) + 1 (bias)] * d\n",
    "    * Peso dos filtros: k * k * p\n",
    "    * Número de filtros/neuronios: d\n",
    "        * Cada um gera um mapa de ativação\n",
    "    * + 1 é o termo bias de cada filtro\n",
    "\n",
    "- Exemplo: entrada 32 * 32 * 3 e 3 camadas\n",
    "    - Conv.layer 1: k = 5 e d = 8\n",
    "    - Conv.layer 2: k = 3 e d = 16\n",
    "    - Conv.layer 3: k = 1 e d = 32\n",
    "\n",
    "* \\# params Conv.layer 1 = [(5 * 5 * 3) + 1] * 8 = 608\n",
    "* \\# params Conv.layer 2 = [(3 * 3 * 8) + 1] * 16 = 1168\n",
    "* \\# params Conv.layer 3 = [(1 * 1 * 16) + 1] * 32 = 544\n",
    "\n",
    "- obs: Por que usar um filtro 1 por 1? Ele faz uma convolução só em profundidade, combinando cada cada pixel de cada imagem na mesma posição \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "* Opera sobre cada mapa de ativação, reduzindo a dimensão lateral\n",
    "    * Max pooling: operação de máximo local\n",
    "    * Average pooling: operação de média local\n",
    "\n",
    "- Exemplo:\n",
    "    - <img src=\"max_pooling.jpg\" width=\"400\"> \n",
    "\n",
    "* *obs: usar stride > 1 pode substituir o pooling*\n",
    "\n",
    "-  Reduzir o tamanho da entrada permite que o filtro opere em **regiões maiores da imagem**\n",
    "    - Empilhamento de camadas convolucionais aumenta o campo receptivo local não necessitando manter a resolução de entrada\n",
    "    - No exemplo o uso de filtros fez com que o mesmo filtro em um primeiro momento que pegava a íris da pessoa, na ultima imagem passou a pegar quase metade do rosto dela\n",
    "    - <img src=\"pooling.jpg\" width=\"400\"> \n",
    "\n",
    "### Global Pooling\n",
    "\n",
    "* Obtém um valor por canal, como se o tamanho de pool fosse igual as dimensões laterais\n",
    "    * Pooling normal: imagem 40x40, pooling de 2x2 -> imagem final de 20x20\n",
    "    * Global pooling: imagem 40x40, pooling de 40x40 -> imagem final de 1x1\n",
    "\n",
    "- A saída será a média (ou máximo) de uma matriz com só as dimensões de cada canal\n",
    "    - Exemplo: numa entrada com 40 × 40 × 100, a saída será 100 dimensões\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camadas densas e saída\n",
    "\n",
    "* Aplicando o pooling já visto com as convoluções\n",
    "    * <img src=\"CNN.jpg\" width=\"600\"> \n",
    "\n",
    "- No fim, aplicamos uma **camada densa fully connected (FC)**\n",
    "    - Similiar a de uma MultiLayer Perceptron\n",
    "    - Pode ser vista como uma projeção dos dados em uma dimensionalidade arbitrária\n",
    "    - <img src=\"CNN_comFC.jpg\" width=\"600\">\n",
    "\n",
    "* *obs: camada densa pode ser do tipo flatten -> transformar várias camadas em um só vetor*\n",
    "\n",
    "- **Saída**: comumente densa (ex: classificação e regressão)\n",
    "    - Pode ser vista como um vetor de distribuição de probabilidaaes (tipo softmax)\n",
    "    - Não é densa em redes completamente convolucionas (Fully Convolutional Newtowrks, FCN) que serão vistas pra frente\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
